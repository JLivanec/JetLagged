{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xg-Q4r_i_-PG","outputId":"f36a96b3-2202-4ce8-efd7-b9ccb503f009","executionInfo":{"status":"ok","timestamp":1734207400518,"user_tz":300,"elapsed":21451,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting noaa-sdk\n","  Downloading noaa_sdk-0.1.21-py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from noaa-sdk) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->noaa-sdk) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->noaa-sdk) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->noaa-sdk) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->noaa-sdk) (2024.8.30)\n","Downloading noaa_sdk-0.1.21-py3-none-any.whl (11 kB)\n","Installing collected packages: noaa-sdk\n","Successfully installed noaa-sdk-0.1.21\n","Collecting meteostat\n","  Downloading meteostat-1.6.8-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from meteostat) (2.2.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from meteostat) (2024.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from meteostat) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->meteostat) (2.8.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->meteostat) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.17.0)\n","Downloading meteostat-1.6.8-py3-none-any.whl (31 kB)\n","Installing collected packages: meteostat\n","Successfully installed meteostat-1.6.8\n"]}],"source":["%pip install noaa-sdk\n","%pip install meteostat\n","#%pip install xgboost\n","#%pip install imblearn\n","#%pip install scikit-learn\n","#%pip install torch\n","#%pip install typing_extensions"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"e3YBnAyaih8j","executionInfo":{"status":"ok","timestamp":1734207418638,"user_tz":300,"elapsed":18123,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from noaa_sdk import NOAA\n","from meteostat import Point, Hourly\n","from datetime import datetime, timedelta, date\n","import pytz\n","import re\n","import requests\n","import pickle\n","import xgboost as xgb\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import OneClassSVM\n","from imblearn.under_sampling import RandomUnderSampler\n","import math\n","from sklearn.preprocessing import MinMaxScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import joblib\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import pytz\n","from imblearn.over_sampling import SMOTE\n","from sklearn.utils import shuffle\n","import networkx as nx\n","from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4zGuoqih7iv","outputId":"9f75b71a-3b02-4b32-8d91-3306c4647223","executionInfo":{"status":"ok","timestamp":1734207440249,"user_tz":300,"elapsed":21614,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"tp6CkJJVil4k","executionInfo":{"status":"ok","timestamp":1734207440249,"user_tz":300,"elapsed":3,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[],"source":["import os\n","import sys\n","# Get the current working directory\n","dir_path = '/content/gdrive/My Drive/JetLagged/data'\n","sys.path.append(dir_path)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31XU0u4TM0b_","outputId":"5ddaf5f0-d573-41f1-8636-70a6c3642d46","executionInfo":{"status":"ok","timestamp":1734207557689,"user_tz":300,"elapsed":50206,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Unnamed: 0                       int64\n","Date                            object\n","Destination Airport Code        object\n","Origin Airport Code             object\n","Direction                       object\n","Departure Count                  int64\n","Departure Delay                  int64\n","Departure Delay > 15 Min        object\n","Arrival Delay                    int64\n","Arrival Delay > 15 Min          object\n","Cancelled Flight                object\n","Scheduled Departure Time        object\n","Actual Departure Time           object\n","Arrival Delay Air System         int64\n","Arrival Delay Weather            int64\n","Arrival Delay Group Code       float64\n","Aircraft Type                   object\n","Mkt. Carrier Code               object\n","Op. Carrier Code                object\n","Actual Arrival Time             object\n","Scheduled Arrival Time          object\n","Departure Delay Group Code     float64\n","Arrival Delay Carrier            int64\n","Arrival Delay Late Aircraft      int64\n","Arrival Delay Security           int64\n","code                            object\n","latitude                       float64\n","longitude                      float64\n","elevation                        int64\n","time_zone                       object\n","Scheduled Departure UTC         object\n","hour_bin_x                      object\n","index                           object\n","temp                           float64\n","dwpt                           float64\n","rhum                           float64\n","prcp                           float64\n","snow                           float64\n","wdir                           float64\n","wspd                           float64\n","wpgt                           float64\n","pres                           float64\n","tsun                           float64\n","coco                           float64\n","hour_bin_y                      object\n","dtype: object\n"]}],"source":["# The commented code below is the preprocessing task, it takes too much time so I ran the code in local and loading the completed csv here\n","\n","# schedules_df = pd.read_csv(\"{}/OTP_DETAIL_UC_LARGE_HUB_1123971.csv\".format(dir_path))\n","# schedules_df = schedules_df.dropna(subset=['Origin Airport Code'])\n","# airport_info_df = pd.read_csv(\"{}/airports_info.csv\".format(dir_path))\n","# airport_info_df = airport_info_df[['code', 'latitude','longitude', 'elevation','time_zone']]\n","# print(schedules_df.columns)\n","# print(airport_info_df.columns)\n","\n","flight_weather = pd.read_csv(\"{}/processed/flight_weather_UTC.csv\".format(dir_path), low_memory=False)\n","print(flight_weather.dtypes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGiVTWlm7IFx"},"outputs":[],"source":["# flight_df = pd.merge(schedules_df, airport_info_df, left_on='Origin Airport Code', right_on='code')\n","# print(flight_df.head(4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXOltQfR8vfG"},"outputs":[],"source":["# def convert_to_utc(row):\n","#   dep_time = datetime.strptime(row['Scheduled Departure Time'], '%H:%M').time()\n","#   date = pd.to_datetime(row['Date']).date()\n","#   local_dt = datetime.combine(date, dep_time)\n","#   local_tz = pytz.timezone(row['time_zone'])\n","#   local_dt = local_tz.localize(local_dt)\n","#   utc_dt = local_dt.astimezone(pytz.UTC)\n","#   return utc_dt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgI6C4Ev91wG"},"outputs":[],"source":["# flight_weather[\"Scheduled Departure UTC\"] = flight_weather.apply(convert_to_utc, axis=1)\n","# # print(flight_weather)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PX25hoSDR-u"},"outputs":[],"source":["# def fetch_weather(row):\n","#     # target_time = row['hour_bin'].tz_convert(None)\n","#     start = row['hour_bin']\n","#     end = start + pd.Timedelta(hours=1)\n","\n","#     location = Point(row['latitude'], row['longitude'], row['elevation'])\n","#     hourly_data = Hourly(location, start, end).fetch()\n","#     hourly_data['Origin Airport Code'] = row['Origin Airport Code']\n","#     hourly_data['hour_bin'] = row['hour_bin']\n","\n","#     return hourly_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ot7vhVu92t9"},"outputs":[],"source":["\n","# flight_df['hour_bin'] = flight_df['Scheduled Departure UTC'].dt.floor('h').dt.tz_convert(None)\n","# unique_times = flight_df[['Origin Airport Code', 'latitude', 'elevation','longitude', 'hour_bin']].drop_duplicates()\n","\n","# weather_data= []\n","# weather_data = unique_times.apply(fetch_weather, axis=1).tolist()\n","# weather_df = pd.concat(weather_data).reset_index()\n","# print(weather_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1qBQ5mzyPSDc"},"outputs":[],"source":["\n","# flight_weather = pd.merge(flight_df, weather_df, left_on=['Origin Airport Code', 'hour_bin'],\n","#                      right_on=['Origin Airport Code', 'time'], how='left')"]},{"cell_type":"markdown","metadata":{"id":"KwDQUBwnP5BK"},"source":["# Data Exploration and Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"sUodbDDGWZ-U","outputId":"8a9b93c2-0e6a-4be2-cbe8-f0ebc3336166","executionInfo":{"status":"ok","timestamp":1734054015721,"user_tz":300,"elapsed":10,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Unnamed: 0                                             0\n","Date                                          01/01/2023\n","Destination Airport Code                             AUS\n","Origin Airport Code                                  ATL\n","Direction                                       Outbound\n","Departure Count                                        1\n","Departure Delay                                        0\n","Departure Delay > 15 Min                              No\n","Arrival Delay                                          0\n","Arrival Delay > 15 Min                                No\n","Cancelled Flight                                      No\n","Scheduled Departure Time                           09:49\n","Actual Departure Time                              09:48\n","Arrival Delay Air System                               0\n","Arrival Delay Weather                                  0\n","Arrival Delay Group Code                            -2.0\n","Aircraft Type                                        321\n","Mkt. Carrier Code                                     DL\n","Op. Carrier Code                                      DL\n","Actual Arrival Time                                11:03\n","Scheduled Arrival Time                             11:23\n","Departure Delay Group Code                          -1.0\n","Arrival Delay Carrier                                  0\n","Arrival Delay Late Aircraft                            0\n","Arrival Delay Security                                 0\n","code                                                 ATL\n","latitude                                       33.637799\n","longitude                                     -84.429271\n","elevation                                           1049\n","time_zone                               America/New_York\n","Scheduled Departure UTC        2023-01-01 14:49:00+00:00\n","hour_bin_x                           2023-01-01 14:00:00\n","index                                                NaN\n","temp                                                 NaN\n","dwpt                                                 NaN\n","rhum                                                 NaN\n","prcp                                                 NaN\n","snow                                                 NaN\n","wdir                                                 NaN\n","wspd                                                 NaN\n","wpgt                                                 NaN\n","pres                                                 NaN\n","tsun                                                 NaN\n","coco                                                 NaN\n","hour_bin_y                                           NaN\n","Name: 0, dtype: object"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Unnamed: 0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <td>01/01/2023</td>\n","    </tr>\n","    <tr>\n","      <th>Destination Airport Code</th>\n","      <td>AUS</td>\n","    </tr>\n","    <tr>\n","      <th>Origin Airport Code</th>\n","      <td>ATL</td>\n","    </tr>\n","    <tr>\n","      <th>Direction</th>\n","      <td>Outbound</td>\n","    </tr>\n","    <tr>\n","      <th>Departure Count</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Departure Delay</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Departure Delay &gt; 15 Min</th>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay &gt; 15 Min</th>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>Cancelled Flight</th>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>Scheduled Departure Time</th>\n","      <td>09:49</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Departure Time</th>\n","      <td>09:48</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay Air System</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay Weather</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay Group Code</th>\n","      <td>-2.0</td>\n","    </tr>\n","    <tr>\n","      <th>Aircraft Type</th>\n","      <td>321</td>\n","    </tr>\n","    <tr>\n","      <th>Mkt. Carrier Code</th>\n","      <td>DL</td>\n","    </tr>\n","    <tr>\n","      <th>Op. Carrier Code</th>\n","      <td>DL</td>\n","    </tr>\n","    <tr>\n","      <th>Actual Arrival Time</th>\n","      <td>11:03</td>\n","    </tr>\n","    <tr>\n","      <th>Scheduled Arrival Time</th>\n","      <td>11:23</td>\n","    </tr>\n","    <tr>\n","      <th>Departure Delay Group Code</th>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay Carrier</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay Late Aircraft</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Arrival Delay Security</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>code</th>\n","      <td>ATL</td>\n","    </tr>\n","    <tr>\n","      <th>latitude</th>\n","      <td>33.637799</td>\n","    </tr>\n","    <tr>\n","      <th>longitude</th>\n","      <td>-84.429271</td>\n","    </tr>\n","    <tr>\n","      <th>elevation</th>\n","      <td>1049</td>\n","    </tr>\n","    <tr>\n","      <th>time_zone</th>\n","      <td>America/New_York</td>\n","    </tr>\n","    <tr>\n","      <th>Scheduled Departure UTC</th>\n","      <td>2023-01-01 14:49:00+00:00</td>\n","    </tr>\n","    <tr>\n","      <th>hour_bin_x</th>\n","      <td>2023-01-01 14:00:00</td>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>temp</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>dwpt</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>rhum</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>prcp</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>snow</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>wdir</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>wspd</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>wpgt</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>pres</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>tsun</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>coco</th>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>hour_bin_y</th>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"]},"metadata":{},"execution_count":35}],"source":["# row sample\n","flight_weather.iloc[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YNMv8lpVWI6a","outputId":"2d3ac88b-4e93-4283-de39-7635618b726a","executionInfo":{"status":"ok","timestamp":1734054015721,"user_tz":300,"elapsed":8,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of total data frame rows: 4015685\n"]}],"source":["print(\"Number of total data frame rows: \" + str(len(flight_weather)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9FcW7KZWyew","outputId":"3a99508f-2f66-4611-bc48-a248ae684a27","executionInfo":{"status":"ok","timestamp":1734054018324,"user_tz":300,"elapsed":2610,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of rows present in dataset where there is populated weather data: 2859569\n"]}],"source":["flight_weather_sub = flight_weather.dropna(subset=['temp'])\n","print(\"Number of rows present in dataset where there is populated weather data: \" + str(len(flight_weather_sub)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"id":"uMUsdP90XixW","outputId":"a3eb90a5-7d66-4fb5-bde7-d159fe3fade4","executionInfo":{"status":"ok","timestamp":1734054021094,"user_tz":300,"elapsed":2772,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         Unnamed: 0  Departure Count  Departure Delay  Arrival Delay  \\\n","count  2.859569e+06        2859569.0     2.859569e+06   2.859569e+06   \n","mean   2.130137e+06              1.0     1.765674e+01   1.734527e+01   \n","std    1.109403e+06              0.0     5.761902e+01   5.683850e+01   \n","min    1.522560e+05              1.0     0.000000e+00   0.000000e+00   \n","25%    1.355644e+06              1.0     0.000000e+00   0.000000e+00   \n","50%    2.178264e+06              1.0     0.000000e+00   0.000000e+00   \n","75%    3.142408e+06              1.0     1.100000e+01   1.100000e+01   \n","max    4.015684e+06              1.0     2.905000e+03   2.912000e+03   \n","\n","       Arrival Delay Air System  Arrival Delay Weather  \\\n","count              2.859569e+06           2.859569e+06   \n","mean               3.520227e+00           6.846039e-01   \n","std                1.733368e+01           1.232621e+01   \n","min                0.000000e+00           0.000000e+00   \n","25%                0.000000e+00           0.000000e+00   \n","50%                0.000000e+00           0.000000e+00   \n","75%                0.000000e+00           0.000000e+00   \n","max                1.409000e+03           1.440000e+03   \n","\n","       Arrival Delay Group Code  Departure Delay Group Code  \\\n","count              2.809958e+06                2.819867e+06   \n","mean              -2.633990e-02                3.078514e-01   \n","std                2.675269e+00                2.504881e+00   \n","min               -2.000000e+00               -2.000000e+00   \n","25%               -2.000000e+00               -1.000000e+00   \n","50%               -1.000000e+00               -1.000000e+00   \n","75%                0.000000e+00                0.000000e+00   \n","max                1.200000e+01                1.200000e+01   \n","\n","       Arrival Delay Carrier  Arrival Delay Late Aircraft  ...          dwpt  \\\n","count           2.859569e+06                 2.859569e+06  ...  2.859569e+06   \n","mean            5.841739e+00                 6.253631e+00  ...  1.081396e+01   \n","std             3.768604e+01                 3.265944e+01  ...  8.959610e+00   \n","min             0.000000e+00                 0.000000e+00  ... -3.510000e+01   \n","25%             0.000000e+00                 0.000000e+00  ...  4.800000e+00   \n","50%             0.000000e+00                 0.000000e+00  ...  1.190000e+01   \n","75%             0.000000e+00                 0.000000e+00  ...  1.810000e+01   \n","max             2.827000e+03                 2.557000e+03  ...  2.810000e+01   \n","\n","               rhum          prcp  snow          wdir          wspd  wpgt  \\\n","count  2.859569e+06  2.859569e+06   0.0  2.859569e+06  2.859569e+06   0.0   \n","mean   6.574508e+01  1.358373e-01   NaN  1.768747e+02  1.352005e+01   NaN   \n","std    1.883642e+01  1.089180e+00   NaN  1.116884e+02  8.111955e+00   NaN   \n","min    7.000000e+00  0.000000e+00   NaN  0.000000e+00  0.000000e+00   NaN   \n","25%    5.200000e+01  0.000000e+00   NaN  8.000000e+01  7.600000e+00   NaN   \n","50%    6.700000e+01  0.000000e+00   NaN  1.900000e+02  1.300000e+01   NaN   \n","75%    8.100000e+01  0.000000e+00   NaN  2.700000e+02  1.840000e+01   NaN   \n","max    1.000000e+02  6.380000e+01   NaN  3.600000e+02  7.960000e+01   NaN   \n","\n","               pres  tsun          coco  \n","count  2.859569e+06   0.0  2.859569e+06  \n","mean   1.016111e+03   NaN  3.387448e+00  \n","std    6.286164e+00   NaN  2.711798e+00  \n","min    9.806000e+02   NaN  1.000000e+00  \n","25%    1.012500e+03   NaN  2.000000e+00  \n","50%    1.015900e+03   NaN  3.000000e+00  \n","75%    1.019900e+03   NaN  3.000000e+00  \n","max    1.041800e+03   NaN  2.500000e+01  \n","\n","[8 rows x 25 columns]"],"text/html":["\n","  <div id=\"df-9a544bcc-1953-47cc-99ac-0161c1212603\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Departure Count</th>\n","      <th>Departure Delay</th>\n","      <th>Arrival Delay</th>\n","      <th>Arrival Delay Air System</th>\n","      <th>Arrival Delay Weather</th>\n","      <th>Arrival Delay Group Code</th>\n","      <th>Departure Delay Group Code</th>\n","      <th>Arrival Delay Carrier</th>\n","      <th>Arrival Delay Late Aircraft</th>\n","      <th>...</th>\n","      <th>dwpt</th>\n","      <th>rhum</th>\n","      <th>prcp</th>\n","      <th>snow</th>\n","      <th>wdir</th>\n","      <th>wspd</th>\n","      <th>wpgt</th>\n","      <th>pres</th>\n","      <th>tsun</th>\n","      <th>coco</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2.859569e+06</td>\n","      <td>2859569.0</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>2.809958e+06</td>\n","      <td>2.819867e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>...</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>0.0</td>\n","      <td>2.859569e+06</td>\n","      <td>2.859569e+06</td>\n","      <td>0.0</td>\n","      <td>2.859569e+06</td>\n","      <td>0.0</td>\n","      <td>2.859569e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.130137e+06</td>\n","      <td>1.0</td>\n","      <td>1.765674e+01</td>\n","      <td>1.734527e+01</td>\n","      <td>3.520227e+00</td>\n","      <td>6.846039e-01</td>\n","      <td>-2.633990e-02</td>\n","      <td>3.078514e-01</td>\n","      <td>5.841739e+00</td>\n","      <td>6.253631e+00</td>\n","      <td>...</td>\n","      <td>1.081396e+01</td>\n","      <td>6.574508e+01</td>\n","      <td>1.358373e-01</td>\n","      <td>NaN</td>\n","      <td>1.768747e+02</td>\n","      <td>1.352005e+01</td>\n","      <td>NaN</td>\n","      <td>1.016111e+03</td>\n","      <td>NaN</td>\n","      <td>3.387448e+00</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.109403e+06</td>\n","      <td>0.0</td>\n","      <td>5.761902e+01</td>\n","      <td>5.683850e+01</td>\n","      <td>1.733368e+01</td>\n","      <td>1.232621e+01</td>\n","      <td>2.675269e+00</td>\n","      <td>2.504881e+00</td>\n","      <td>3.768604e+01</td>\n","      <td>3.265944e+01</td>\n","      <td>...</td>\n","      <td>8.959610e+00</td>\n","      <td>1.883642e+01</td>\n","      <td>1.089180e+00</td>\n","      <td>NaN</td>\n","      <td>1.116884e+02</td>\n","      <td>8.111955e+00</td>\n","      <td>NaN</td>\n","      <td>6.286164e+00</td>\n","      <td>NaN</td>\n","      <td>2.711798e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.522560e+05</td>\n","      <td>1.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-2.000000e+00</td>\n","      <td>-2.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>-3.510000e+01</td>\n","      <td>7.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>NaN</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>NaN</td>\n","      <td>9.806000e+02</td>\n","      <td>NaN</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.355644e+06</td>\n","      <td>1.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-2.000000e+00</td>\n","      <td>-1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>4.800000e+00</td>\n","      <td>5.200000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>NaN</td>\n","      <td>8.000000e+01</td>\n","      <td>7.600000e+00</td>\n","      <td>NaN</td>\n","      <td>1.012500e+03</td>\n","      <td>NaN</td>\n","      <td>2.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.178264e+06</td>\n","      <td>1.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-1.000000e+00</td>\n","      <td>-1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>1.190000e+01</td>\n","      <td>6.700000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>NaN</td>\n","      <td>1.900000e+02</td>\n","      <td>1.300000e+01</td>\n","      <td>NaN</td>\n","      <td>1.015900e+03</td>\n","      <td>NaN</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.142408e+06</td>\n","      <td>1.0</td>\n","      <td>1.100000e+01</td>\n","      <td>1.100000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>1.810000e+01</td>\n","      <td>8.100000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>NaN</td>\n","      <td>2.700000e+02</td>\n","      <td>1.840000e+01</td>\n","      <td>NaN</td>\n","      <td>1.019900e+03</td>\n","      <td>NaN</td>\n","      <td>3.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>4.015684e+06</td>\n","      <td>1.0</td>\n","      <td>2.905000e+03</td>\n","      <td>2.912000e+03</td>\n","      <td>1.409000e+03</td>\n","      <td>1.440000e+03</td>\n","      <td>1.200000e+01</td>\n","      <td>1.200000e+01</td>\n","      <td>2.827000e+03</td>\n","      <td>2.557000e+03</td>\n","      <td>...</td>\n","      <td>2.810000e+01</td>\n","      <td>1.000000e+02</td>\n","      <td>6.380000e+01</td>\n","      <td>NaN</td>\n","      <td>3.600000e+02</td>\n","      <td>7.960000e+01</td>\n","      <td>NaN</td>\n","      <td>1.041800e+03</td>\n","      <td>NaN</td>\n","      <td>2.500000e+01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 25 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a544bcc-1953-47cc-99ac-0161c1212603')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9a544bcc-1953-47cc-99ac-0161c1212603 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9a544bcc-1953-47cc-99ac-0161c1212603');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-49650cf6-53dd-42bf-901d-3d8516b79736\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49650cf6-53dd-42bf-901d-3d8516b79736')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-49650cf6-53dd-42bf-901d-3d8516b79736 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{},"execution_count":38}],"source":["flight_weather_sub.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgMZg_mk03-B"},"outputs":[],"source":["def bucket_direction(direction):\n","    # Define cardinal direction buckets\n","    buckets = np.arange(0, 360, 22.5)\n","    closest_bucket = min(buckets, key=lambda x: abs(x - direction))\n","    return closest_bucket"]},{"cell_type":"markdown","metadata":{"id":"XzY8YAGVdLI2"},"source":["These cells flag certain dates based on the criteria outlined here:\n","\n","https://www.oag.com/blog/busiest-days-for-air-travel-2009-2024\n","\n","https://www.nerdwallet.com/article/travel/busiest-days-to-fly-during-winter-holidays-2023"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tX6QyfBCaq43"},"outputs":[],"source":["# returns true if the given day is a friday, saturday, or sunday\n","def is_travel_day(d) :\n","    return d.weekday() >= 4\n","\n","# returns true if the given day is within the first two weeks of august\n","def is_summer_travel_season(d) :\n","    if d.month != 8:\n","        return False\n","\n","    # count number of fridays which have occurred in august\n","    fri_count = sum(1 for day in range(1, d.day + 1) if date(d.year, 8, day).weekday() == 4)\n","    beginning_august = d.month == 8 and fri_count in [1, 2]\n","    jul = d.month == 7\n","\n","    return beginning_august or jul\n","\n","def thanksgiving_travel(d):\n","    # Find Thanksgiving (4th Thursday of November)\n","    first_day_of_november = date(d.year, 11, 1)\n","    first_thursday = (3 - first_day_of_november.weekday() + 7) % 7\n","    thanksgiving = first_day_of_november + timedelta(days=first_thursday + 21)\n","\n","    # Map each travel day to its calculated date\n","    travel_days = [\n","        thanksgiving + timedelta(days=3),  # Sunday after Thanksgiving\n","        thanksgiving - timedelta(days=1),  # Wednesday before Thanksgiving\n","        thanksgiving - timedelta(days=6),  # Friday before Thanksgiving\n","        thanksgiving + timedelta(days=4),  # Monday after Thanksgiving (Cyber Monday)\n","        thanksgiving + timedelta(days=2),  # Saturday after Thanksgiving\n","        thanksgiving - timedelta(days=4),  # Sunday before Thanksgiving\n","        thanksgiving - timedelta(days=2),  # Tuesday before Thanksgiving\n","        thanksgiving - timedelta(days=7),  # Thursday before Thanksgiving\n","        thanksgiving - timedelta(days=3),  # Monday before Thanksgiving\n","        thanksgiving - timedelta(days=5),  # Saturday before Thanksgiving\n","        thanksgiving + timedelta(days=7),  # Thursday after Thanksgiving\n","        thanksgiving + timedelta(days=5),  # Tuesday after Thanksgiving (Giving Tuesday)\n","        thanksgiving + timedelta(days=1),  # Friday after Thanksgiving (Black Friday)\n","        thanksgiving + timedelta(days=6),  # Wednesday after Thanksgiving\n","        thanksgiving,                     # Thanksgiving Day (Thursday)\n","    ]\n","\n","    # Return True if the date matches any busy travel day\n","    return d in travel_days\n","\n","def holiday_travel(d):\n","    holiday_travel = [\n","        (12, 27),  # December 27\n","        (12, 30),  # December 30\n","        (12, 20),  # December 20\n","        (12, 26),  # December 26\n","        (12, 23),  # December 23\n","        (12, 22),  # December 22\n","        (12, 19),  # December 19\n","        (12, 21),  # December 21\n","        (12, 29),  # December 29\n","        (12, 28),  # December 28\n","        (12, 18),  # December 18\n","        (1, 1),    # January 1 (New Year’s Day)\n","        (12, 31),  # December 31 (New Year’s Eve)\n","        (12, 24),  # December 24 (Christmas Eve)\n","        (12, 25),  # December 25 (Christmas Day)\n","    ]\n","\n","    # Check if the input date's month and day match any of the dates\n","    return (d.month, d.day) in holiday_travel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvjlOkboYNbZ","outputId":"73064164-c20e-46ce-aff9-a802befd3922","executionInfo":{"status":"ok","timestamp":1734054123767,"user_tz":300,"elapsed":102675,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["flight_weather_sub['Departure Delay > 15 Min'] = flight_weather_sub['Departure Delay > 15 Min'].map({'Yes': 1, 'No': 0})\n","flight_weather_sub['Arrival Delay > 15 Min'] = flight_weather_sub['Arrival Delay > 15 Min'].map({'Yes': 1, 'No': 0})\n","flight_weather_sub['Cancelled Flight'] = flight_weather_sub['Cancelled Flight'].map({'Yes': 1, 'No': 0})\n","flight_weather_sub['gust'] = flight_weather_sub['wpgt'].fillna(flight_weather_sub['wspd'])\n","flight_weather_sub['precip_chance'] = flight_weather_sub['prcp'].apply(lambda x: 100 if not x == 0 else 0)\n","flight_weather_sub['wdir'] = flight_weather_sub['wdir'].apply(lambda x: bucket_direction(x))\n","flight_weather_sub['weekend'] = pd.to_datetime(flight_weather_sub['Date']).apply(lambda x: 1 if is_travel_day(x) else 0)\n","flight_weather_sub['summer_travel'] = pd.to_datetime(flight_weather_sub['Date']).apply(lambda x: 1 if is_summer_travel_season(x) else 0)\n","flight_weather_sub['thanksgiving'] = pd.to_datetime(flight_weather_sub['Date']).apply(lambda x: 1 if thanksgiving_travel(x) else 0)\n","flight_weather_sub['holiday'] = pd.to_datetime(flight_weather_sub['Date']).apply(lambda x: 1 if holiday_travel(x) else 0)"]},{"cell_type":"markdown","metadata":{"id":"So0IsjW9cDXF"},"source":[]},{"cell_type":"markdown","metadata":{"id":"dIxCtGCEb_5h"},"source":["Create a new dataframe of only flights that were not cancelled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gRAuO9XibxV8"},"outputs":[],"source":["non_cancelled_flights = flight_weather_sub[flight_weather_sub['Cancelled Flight'] == 0]"]},{"cell_type":"markdown","metadata":{"id":"F1CMcO9N8upF"},"source":["Extremely skewed classification, so let's take all delayed flights then an equal number of flights not delayed as our sample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bp9QIei2_jog","outputId":"957f8fc1-4c8c-43ee-ba92-3119afa87210","executionInfo":{"status":"ok","timestamp":1734055134460,"user_tz":300,"elapsed":188140,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["# Filter relevant columns for the network\n","non_cancelled_flights_filtered = non_cancelled_flights[['Origin Airport Code', 'Destination Airport Code', 'Departure Count']]\n","\n","# Create a directed graph\n","G = nx.DiGraph()\n","\n","# Add weighted edges based on Departure Count\n","for _, row in non_cancelled_flights_filtered.iterrows():\n","    origin = row['Origin Airport Code']\n","    destination = row['Destination Airport Code']\n","    weight = row['Departure Count']\n","    if G.has_edge(origin, destination):\n","        # If the edge already exists, update the weight\n","        G[origin][destination]['weight'] += weight\n","    else:\n","        # Add a new edge with the weight\n","        G.add_edge(origin, destination, weight=weight)\n","\n","# Calculate centrality measures\n","degree_centrality = nx.degree_centrality(G)\n","closeness_centrality = nx.closeness_centrality(G)\n","betweenness_centrality = nx.betweenness_centrality(G, normalized=True, weight='weight')\n","\n","# Add centrality features to the dataframe\n","non_cancelled_flights['Degree Centrality Arrival'] = non_cancelled_flights['Destination Airport Code'].map(degree_centrality)\n","non_cancelled_flights['Closeness Centrality Arrival'] = non_cancelled_flights['Destination Airport Code'].map(closeness_centrality)\n","non_cancelled_flights['Betweenness Centrality Arrival'] = non_cancelled_flights['Destination Airport Code'].map(betweenness_centrality)\n","\n","non_cancelled_flights['Degree Centrality Departure'] = non_cancelled_flights['Origin Airport Code'].map(degree_centrality)\n","non_cancelled_flights['Closeness Centrality Departure'] = non_cancelled_flights['Origin Airport Code'].map(closeness_centrality)\n","non_cancelled_flights['Betweenness Centrality Departure'] = non_cancelled_flights['Origin Airport Code'].map(betweenness_centrality)\n","\n","# Save the network\n","pickle.dump(G, open('{}/flight_network.pickle'.format(dir_path), 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Suyyc__T_ysx","outputId":"89cde7b3-0261-4772-f87d-e28b736d3d0f","executionInfo":{"status":"ok","timestamp":1734049584741,"user_tz":300,"elapsed":5212,"user":{"displayName":"Nhan Hoang","userId":"18009007581142331657"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["        Unnamed: 0       Date Destination Airport Code Origin Airport Code  \\\n","152256      152256 2023-01-01                      ATL                 AUS   \n","152257      152257 2023-01-01                      ATL                 AUS   \n","152258      152258 2023-01-01                      ATL                 AUS   \n","152259      152259 2023-01-01                      ATL                 AUS   \n","152260      152260 2023-01-01                      ATL                 AUS   \n","\n","       Direction  Departure Count  Departure Delay  Departure Delay > 15 Min  \\\n","152256  Outbound                1                8                         0   \n","152257  Outbound                1                0                         0   \n","152258  Outbound                1                0                         0   \n","152259  Outbound                1                0                         0   \n","152260  Outbound                1                0                         0   \n","\n","        Arrival Delay  Arrival Delay > 15 Min  ...  Month_12 Day_0 Day_1  \\\n","152256              5                       0  ...       0.0   0.0   0.0   \n","152257              0                       0  ...       0.0   0.0   0.0   \n","152258              0                       0  ...       0.0   0.0   0.0   \n","152259              0                       0  ...       0.0   0.0   0.0   \n","152260              0                       0  ...       0.0   0.0   0.0   \n","\n","        Day_2  Day_3  Day_4 Day_5 Day_6 Departure Hour Bucket  \\\n","152256    0.0    0.0    0.0   0.0   1.0                     5   \n","152257    0.0    0.0    0.0   0.0   1.0                     7   \n","152258    0.0    0.0    0.0   0.0   1.0                     7   \n","152259    0.0    0.0    0.0   0.0   1.0                    12   \n","152260    0.0    0.0    0.0   0.0   1.0                    12   \n","\n","       Arrival Hour Bucket  \n","152256                   8  \n","152257                  10  \n","152258                  10  \n","152259                  15  \n","152260                  15  \n","\n","[5 rows x 81 columns]\n","Index(['Unnamed: 0', 'Date', 'Destination Airport Code', 'Origin Airport Code',\n","       'Direction', 'Departure Count', 'Departure Delay',\n","       'Departure Delay > 15 Min', 'Arrival Delay', 'Arrival Delay > 15 Min',\n","       'Cancelled Flight', 'Scheduled Departure Time', 'Actual Departure Time',\n","       'Arrival Delay Air System', 'Arrival Delay Weather',\n","       'Arrival Delay Group Code', 'Aircraft Type', 'Mkt. Carrier Code',\n","       'Op. Carrier Code', 'Actual Arrival Time', 'Scheduled Arrival Time',\n","       'Departure Delay Group Code', 'Arrival Delay Carrier',\n","       'Arrival Delay Late Aircraft', 'Arrival Delay Security', 'code',\n","       'latitude', 'longitude', 'elevation', 'time_zone',\n","       'Scheduled Departure UTC', 'hour_bin_x', 'index', 'temp', 'dwpt',\n","       'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco',\n","       'hour_bin_y', 'gust', 'precip_chance', 'weekend', 'summer_travel',\n","       'thanksgiving', 'holiday', 'Degree Centrality Arrival',\n","       'Closeness Centrality Arrival', 'Betweenness Centrality Arrival',\n","       'Degree Centrality Departure', 'Closeness Centrality Departure',\n","       'Betweenness Centrality Departure', 'Quarter', 'Month', 'Day of Week',\n","       'Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6',\n","       'Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11', 'Month_12',\n","       'Day_0', 'Day_1', 'Day_2', 'Day_3', 'Day_4', 'Day_5', 'Day_6',\n","       'Departure Hour Bucket', 'Arrival Hour Bucket'],\n","      dtype='object')\n","81\n"]},{"output_type":"stream","name":"stderr","text":["SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]}],"source":["# Add Quarter, Month, and Day of Week\n","non_cancelled_flights['Date'] = pd.to_datetime(non_cancelled_flights['Date'], format='%m/%d/%Y')\n","non_cancelled_flights['Quarter'] = non_cancelled_flights['Date'].dt.quarter\n","non_cancelled_flights['Month'] = non_cancelled_flights['Date'].dt.month\n","non_cancelled_flights['Day of Week'] = non_cancelled_flights['Date'].dt.dayofweek\n","\n","# One-hot encode Month and Day of Week\n","encoder = OneHotEncoder(sparse_output=False)\n","month_encoded = encoder.fit_transform(non_cancelled_flights[['Month']])\n","day_of_week_encoded = encoder.fit_transform(non_cancelled_flights[['Day of Week']])\n","\n","# Add encoded features to the dataframe\n","month_columns = [f'Month_{i+1}' for i in range(month_encoded.shape[1])]\n","day_columns = [f'Day_{i}' for i in range(day_of_week_encoded.shape[1])]\n","\n","non_cancelled_flights[month_columns] = month_encoded\n","non_cancelled_flights[day_columns] = day_of_week_encoded\n","\n","# Add Departure and Arrival Time in 1-hour buckets\n","non_cancelled_flights['Scheduled Departure Time'] = pd.to_datetime(non_cancelled_flights['Scheduled Departure Time'], format='%H:%M')\n","non_cancelled_flights['Scheduled Arrival Time'] = pd.to_datetime(non_cancelled_flights['Scheduled Arrival Time'], format='%H:%M')\n","\n","non_cancelled_flights['Departure Hour Bucket'] = non_cancelled_flights['Scheduled Departure Time'].dt.hour\n","non_cancelled_flights['Arrival Hour Bucket'] = non_cancelled_flights['Scheduled Arrival Time'].dt.hour\n","\n","# Final dataframe with all added features\n","print(non_cancelled_flights.head())\n","print(non_cancelled_flights.columns)\n","print(len(non_cancelled_flights.columns))"]},{"cell_type":"markdown","metadata":{"id":"Cacy4OLQrr_R"},"source":["## 50-50 data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561},"id":"FXveMW-Q8z-c","outputId":"371b193a-5fa3-465f-95f0-0d7a17a576c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["0    2180679\n","1     637232\n","Name: Departure Delay > 15 Min, dtype: int64\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Departure Count</th>\n","      <th>Departure Delay</th>\n","      <th>Departure Delay &gt; 15 Min</th>\n","      <th>Arrival Delay</th>\n","      <th>Arrival Delay &gt; 15 Min</th>\n","      <th>Cancelled Flight</th>\n","      <th>Arrival Delay Air System</th>\n","      <th>Arrival Delay Weather</th>\n","      <th>Arrival Delay Group Code</th>\n","      <th>...</th>\n","      <th>Month_12</th>\n","      <th>Day_0</th>\n","      <th>Day_1</th>\n","      <th>Day_2</th>\n","      <th>Day_3</th>\n","      <th>Day_4</th>\n","      <th>Day_5</th>\n","      <th>Day_6</th>\n","      <th>Departure Hour Bucket</th>\n","      <th>Arrival Hour Bucket</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1.274464e+06</td>\n","      <td>1274464.0</td>\n","      <td>1.274464e+06</td>\n","      <td>1274464.0</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1274464.0</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.269949e+06</td>\n","      <td>...</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","      <td>1.274464e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.119938e+06</td>\n","      <td>1.0</td>\n","      <td>3.773961e+01</td>\n","      <td>0.5</td>\n","      <td>3.547497e+01</td>\n","      <td>4.209432e-01</td>\n","      <td>0.0</td>\n","      <td>5.906378e+00</td>\n","      <td>1.524449e+00</td>\n","      <td>1.162990e+00</td>\n","      <td>...</td>\n","      <td>7.930863e-02</td>\n","      <td>1.476872e-01</td>\n","      <td>1.353063e-01</td>\n","      <td>1.389031e-01</td>\n","      <td>1.467488e-01</td>\n","      <td>1.507991e-01</td>\n","      <td>1.300311e-01</td>\n","      <td>1.505245e-01</td>\n","      <td>1.372560e+01</td>\n","      <td>1.521797e+01</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.101010e+06</td>\n","      <td>0.0</td>\n","      <td>8.159670e+01</td>\n","      <td>0.5</td>\n","      <td>8.102854e+01</td>\n","      <td>4.937107e-01</td>\n","      <td>0.0</td>\n","      <td>2.430169e+01</td>\n","      <td>1.842366e+01</td>\n","      <td>3.464032e+00</td>\n","      <td>...</td>\n","      <td>2.702200e-01</td>\n","      <td>3.547898e-01</td>\n","      <td>3.420506e-01</td>\n","      <td>3.458455e-01</td>\n","      <td>3.538554e-01</td>\n","      <td>3.578531e-01</td>\n","      <td>3.363378e-01</td>\n","      <td>3.575849e-01</td>\n","      <td>4.931444e+00</td>\n","      <td>5.507390e+00</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.522630e+05</td>\n","      <td>1.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-2.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.360968e+06</td>\n","      <td>1.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>-1.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>9.000000e+00</td>\n","      <td>1.100000e+01</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2.164374e+06</td>\n","      <td>1.0</td>\n","      <td>1.450000e+01</td>\n","      <td>0.5</td>\n","      <td>7.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>1.400000e+01</td>\n","      <td>1.600000e+01</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2.916368e+06</td>\n","      <td>1.0</td>\n","      <td>4.200000e+01</td>\n","      <td>1.0</td>\n","      <td>4.000000e+01</td>\n","      <td>1.000000e+00</td>\n","      <td>0.0</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>2.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>1.800000e+01</td>\n","      <td>2.000000e+01</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>4.015684e+06</td>\n","      <td>1.0</td>\n","      <td>2.905000e+03</td>\n","      <td>1.0</td>\n","      <td>2.912000e+03</td>\n","      <td>1.000000e+00</td>\n","      <td>0.0</td>\n","      <td>1.409000e+03</td>\n","      <td>1.440000e+03</td>\n","      <td>1.200000e+01</td>\n","      <td>...</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>2.300000e+01</td>\n","      <td>2.300000e+01</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 64 columns</p>\n","</div>"],"text/plain":["         Unnamed: 0  Departure Count  Departure Delay  \\\n","count  1.274464e+06        1274464.0     1.274464e+06   \n","mean   2.119938e+06              1.0     3.773961e+01   \n","std    1.101010e+06              0.0     8.159670e+01   \n","min    1.522630e+05              1.0     0.000000e+00   \n","25%    1.360968e+06              1.0     0.000000e+00   \n","50%    2.164374e+06              1.0     1.450000e+01   \n","75%    2.916368e+06              1.0     4.200000e+01   \n","max    4.015684e+06              1.0     2.905000e+03   \n","\n","       Departure Delay > 15 Min  Arrival Delay  Arrival Delay > 15 Min  \\\n","count                 1274464.0   1.274464e+06            1.274464e+06   \n","mean                        0.5   3.547497e+01            4.209432e-01   \n","std                         0.5   8.102854e+01            4.937107e-01   \n","min                         0.0   0.000000e+00            0.000000e+00   \n","25%                         0.0   0.000000e+00            0.000000e+00   \n","50%                         0.5   7.000000e+00            0.000000e+00   \n","75%                         1.0   4.000000e+01            1.000000e+00   \n","max                         1.0   2.912000e+03            1.000000e+00   \n","\n","       Cancelled Flight  Arrival Delay Air System  Arrival Delay Weather  \\\n","count         1274464.0              1.274464e+06           1.274464e+06   \n","mean                0.0              5.906378e+00           1.524449e+00   \n","std                 0.0              2.430169e+01           1.842366e+01   \n","min                 0.0              0.000000e+00           0.000000e+00   \n","25%                 0.0              0.000000e+00           0.000000e+00   \n","50%                 0.0              0.000000e+00           0.000000e+00   \n","75%                 0.0              0.000000e+00           0.000000e+00   \n","max                 0.0              1.409000e+03           1.440000e+03   \n","\n","       Arrival Delay Group Code  ...      Month_12         Day_0  \\\n","count              1.269949e+06  ...  1.274464e+06  1.274464e+06   \n","mean               1.162990e+00  ...  7.930863e-02  1.476872e-01   \n","std                3.464032e+00  ...  2.702200e-01  3.547898e-01   \n","min               -2.000000e+00  ...  0.000000e+00  0.000000e+00   \n","25%               -1.000000e+00  ...  0.000000e+00  0.000000e+00   \n","50%                0.000000e+00  ...  0.000000e+00  0.000000e+00   \n","75%                2.000000e+00  ...  0.000000e+00  0.000000e+00   \n","max                1.200000e+01  ...  1.000000e+00  1.000000e+00   \n","\n","              Day_1         Day_2         Day_3         Day_4         Day_5  \\\n","count  1.274464e+06  1.274464e+06  1.274464e+06  1.274464e+06  1.274464e+06   \n","mean   1.353063e-01  1.389031e-01  1.467488e-01  1.507991e-01  1.300311e-01   \n","std    3.420506e-01  3.458455e-01  3.538554e-01  3.578531e-01  3.363378e-01   \n","min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n","25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n","50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n","75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n","max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n","\n","              Day_6  Departure Hour Bucket  Arrival Hour Bucket  \n","count  1.274464e+06           1.274464e+06         1.274464e+06  \n","mean   1.505245e-01           1.372560e+01         1.521797e+01  \n","std    3.575849e-01           4.931444e+00         5.507390e+00  \n","min    0.000000e+00           0.000000e+00         0.000000e+00  \n","25%    0.000000e+00           9.000000e+00         1.100000e+01  \n","50%    0.000000e+00           1.400000e+01         1.600000e+01  \n","75%    0.000000e+00           1.800000e+01         2.000000e+01  \n","max    1.000000e+00           2.300000e+01         2.300000e+01  \n","\n","[8 rows x 64 columns]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["features = ['Betweenness Centrality Arrival', 'Betweenness Centrality Departure', 'Closeness Centrality Arrival', 'Closeness Centrality Departure','Degree Centrality Arrival', 'Degree Centrality Departure', 'Quarter', 'Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5', 'Month_6',  'Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11', 'Month_12', 'Day_0', 'Day_1', 'Day_2', 'Day_3', 'Day_4', 'Day_5', 'Day_6',\n","'Departure Hour Bucket', 'Arrival Hour Bucket', 'elevation', 'temp', 'dwpt', 'rhum', 'precip_chance', 'wdir', 'wspd', 'gust']\n","\n","unused_features = ['weekend', 'summer_travel', 'thanksgiving', 'holiday']\n","\n","target = 'Departure Delay > 15 Min'\n","print(str(non_cancelled_flights[target].value_counts()))\n","\n","delayed = non_cancelled_flights[non_cancelled_flights[target] == 1]\n","non_delayed = non_cancelled_flights[non_cancelled_flights[target] == 0]\n","# find the number of delays\n","num_delays = len(delayed)\n","sampled_nondelay = non_delayed.sample(n=num_delays, random_state=74)\n","\n","# recombine and shuffle\n","balanced_sample = pd.concat([delayed, sampled_nondelay], ignore_index=True)\n","balanced_sample = balanced_sample.sample(frac=1, random_state=89).reset_index(drop=True)\n","\n","balanced_sample.describe()"]},{"cell_type":"markdown","metadata":{"id":"WznNqcTm83sX"},"source":["Now we'll scale these inputs and save the scaler for future use"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qEdv56J86tH","outputId":"9b6e3052-542f-4a84-ff3e-910ee6c14f9b"},"outputs":[{"data":{"text/plain":["['Z:/VT/F24/urban_computing/JetLagged/data/../models//scaler.pkl']"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["x_unscaled = balanced_sample[features]\n","y = balanced_sample[target]\n","\n","scaler = MinMaxScaler()\n","scaler.fit(x_unscaled)\n","x = scaler.transform(x_unscaled)\n","path = \"{}/../models/\".format(dir_path)\n","joblib.dump(scaler, '{}/scaler.pkl'.format(path))"]},{"cell_type":"markdown","metadata":{"id":"qrHFAFKorr_R"},"source":["## SMOTE Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-Irk-UYrr_R","outputId":"fb0ba500-dab2-458f-afbc-ff4b6798292e"},"outputs":[{"name":"stdout","output_type":"stream","text":["        Betweenness Centrality Arrival  Betweenness Centrality Departure  \\\n","152256                             0.0                          0.062069   \n","152257                             0.0                          0.062069   \n","152258                             0.0                          0.062069   \n","152259                             0.0                          0.062069   \n","152260                             0.0                          0.062069   \n","\n","        Closeness Centrality Arrival  Closeness Centrality Departure  \\\n","152256                      0.633333                        0.568421   \n","152257                      0.633333                        0.568421   \n","152258                      0.633333                        0.568421   \n","152259                      0.633333                        0.568421   \n","152260                      0.633333                        0.568421   \n","\n","        Degree Centrality Arrival  Degree Centrality Departure  Quarter  \\\n","152256                   0.633333                     1.533333        1   \n","152257                   0.633333                     1.533333        1   \n","152258                   0.633333                     1.533333        1   \n","152259                   0.633333                     1.533333        1   \n","152260                   0.633333                     1.533333        1   \n","\n","        Month_1  Month_2  Month_3  ...  Departure Hour Bucket  \\\n","152256      1.0      0.0      0.0  ...                      5   \n","152257      1.0      0.0      0.0  ...                      7   \n","152258      1.0      0.0      0.0  ...                      7   \n","152259      1.0      0.0      0.0  ...                     12   \n","152260      1.0      0.0      0.0  ...                     12   \n","\n","        Arrival Hour Bucket  elevation  temp  dwpt   rhum  precip_chance  \\\n","152256                    8        505   4.1   3.7   97.0              0   \n","152257                   10        505  11.9  11.9  100.0              0   \n","152258                   10        505  11.9  11.9  100.0              0   \n","152259                   15        505  20.8  14.1   66.0              0   \n","152260                   15        505  20.8  14.1   66.0              0   \n","\n","         wdir  wspd  gust  \n","152256  157.5   5.4   5.4  \n","152257  180.0   9.4   9.4  \n","152258  180.0   9.4   9.4  \n","152259  180.0  13.0  13.0  \n","152260  180.0  13.0  13.0  \n","\n","[5 rows x 36 columns]\n","152256    0\n","152257    0\n","152258    0\n","152259    0\n","152260    0\n","Name: Departure Delay > 15 Min, dtype: int64\n","1    1409641\n","0    1408270\n","Name: Departure Delay > 15 Min, dtype: int64\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Betweenness Centrality Arrival</th>\n","      <th>Betweenness Centrality Departure</th>\n","      <th>Closeness Centrality Arrival</th>\n","      <th>Closeness Centrality Departure</th>\n","      <th>Degree Centrality Arrival</th>\n","      <th>Degree Centrality Departure</th>\n","      <th>Quarter</th>\n","      <th>Month_1</th>\n","      <th>Month_2</th>\n","      <th>Month_3</th>\n","      <th>...</th>\n","      <th>Arrival Hour Bucket</th>\n","      <th>elevation</th>\n","      <th>temp</th>\n","      <th>dwpt</th>\n","      <th>rhum</th>\n","      <th>precip_chance</th>\n","      <th>wdir</th>\n","      <th>wspd</th>\n","      <th>gust</th>\n","      <th>Departure Delay &gt; 15 Min</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>...</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","      <td>2.817911e+06</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.064111e-02</td>\n","      <td>3.765743e-02</td>\n","      <td>5.791821e-01</td>\n","      <td>5.411214e-01</td>\n","      <td>1.084199e+00</td>\n","      <td>1.448767e+00</td>\n","      <td>2.478928e+00</td>\n","      <td>8.084654e-02</td>\n","      <td>7.242702e-02</td>\n","      <td>8.929951e-02</td>\n","      <td>...</td>\n","      <td>1.516058e+01</td>\n","      <td>9.260228e+01</td>\n","      <td>1.851464e+01</td>\n","      <td>1.126813e+01</td>\n","      <td>6.575773e+01</td>\n","      <td>9.508711e+00</td>\n","      <td>1.768204e+02</td>\n","      <td>1.382864e+01</td>\n","      <td>1.382864e+01</td>\n","      <td>5.002433e-01</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>3.976359e-02</td>\n","      <td>4.695846e-02</td>\n","      <td>5.589740e-02</td>\n","      <td>5.265382e-02</td>\n","      <td>4.110768e-01</td>\n","      <td>1.510912e-01</td>\n","      <td>1.092023e+00</td>\n","      <td>2.713593e-01</td>\n","      <td>2.580078e-01</td>\n","      <td>2.839153e-01</td>\n","      <td>...</td>\n","      <td>5.494787e+00</td>\n","      <td>1.085165e+02</td>\n","      <td>8.534309e+00</td>\n","      <td>8.970655e+00</td>\n","      <td>1.884177e+01</td>\n","      <td>2.933353e+01</td>\n","      <td>1.092992e+02</td>\n","      <td>8.154236e+00</td>\n","      <td>8.154236e+00</td>\n","      <td>5.000000e-01</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>4.153846e-01</td>\n","      <td>4.153846e-01</td>\n","      <td>5.333333e-01</td>\n","      <td>9.666667e-01</td>\n","      <td>1.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>0.000000e+00</td>\n","      <td>1.300000e+01</td>\n","      <td>-2.290000e+01</td>\n","      <td>-3.510000e+01</td>\n","      <td>7.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000e+00</td>\n","      <td>3.448276e-03</td>\n","      <td>5.424702e-01</td>\n","      <td>5.142857e-01</td>\n","      <td>6.333333e-01</td>\n","      <td>1.366667e+00</td>\n","      <td>2.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>1.100000e+01</td>\n","      <td>2.900000e+01</td>\n","      <td>1.260000e+01</td>\n","      <td>5.400000e+00</td>\n","      <td>5.200000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>9.000000e+01</td>\n","      <td>7.600000e+00</td>\n","      <td>7.600000e+00</td>\n","      <td>0.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000e+00</td>\n","      <td>1.379310e-02</td>\n","      <td>6.000000e-01</td>\n","      <td>5.684211e-01</td>\n","      <td>1.200000e+00</td>\n","      <td>1.500000e+00</td>\n","      <td>2.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>1.600000e+01</td>\n","      <td>4.900000e+01</td>\n","      <td>1.910000e+01</td>\n","      <td>1.240000e+01</td>\n","      <td>6.700000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>1.800000e+02</td>\n","      <td>1.300000e+01</td>\n","      <td>1.300000e+01</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2.298851e-02</td>\n","      <td>6.091954e-02</td>\n","      <td>6.333333e-01</td>\n","      <td>5.684211e-01</td>\n","      <td>1.500000e+00</td>\n","      <td>1.533333e+00</td>\n","      <td>3.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>0.000000e+00</td>\n","      <td>...</td>\n","      <td>2.000000e+01</td>\n","      <td>1.250000e+02</td>\n","      <td>2.530000e+01</td>\n","      <td>1.870000e+01</td>\n","      <td>8.100000e+01</td>\n","      <td>0.000000e+00</td>\n","      <td>2.700000e+02</td>\n","      <td>1.840000e+01</td>\n","      <td>1.840000e+01</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2.793103e-01</td>\n","      <td>2.793103e-01</td>\n","      <td>6.333333e-01</td>\n","      <td>6.000000e-01</td>\n","      <td>1.600000e+00</td>\n","      <td>1.600000e+00</td>\n","      <td>4.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>1.000000e+00</td>\n","      <td>...</td>\n","      <td>2.300000e+01</td>\n","      <td>5.050000e+02</td>\n","      <td>4.250000e+01</td>\n","      <td>2.810000e+01</td>\n","      <td>1.000000e+02</td>\n","      <td>1.000000e+02</td>\n","      <td>3.375000e+02</td>\n","      <td>7.960000e+01</td>\n","      <td>7.960000e+01</td>\n","      <td>1.000000e+00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 37 columns</p>\n","</div>"],"text/plain":["       Betweenness Centrality Arrival  Betweenness Centrality Departure  \\\n","count                    2.817911e+06                      2.817911e+06   \n","mean                     2.064111e-02                      3.765743e-02   \n","std                      3.976359e-02                      4.695846e-02   \n","min                      0.000000e+00                      0.000000e+00   \n","25%                      0.000000e+00                      3.448276e-03   \n","50%                      0.000000e+00                      1.379310e-02   \n","75%                      2.298851e-02                      6.091954e-02   \n","max                      2.793103e-01                      2.793103e-01   \n","\n","       Closeness Centrality Arrival  Closeness Centrality Departure  \\\n","count                  2.817911e+06                    2.817911e+06   \n","mean                   5.791821e-01                    5.411214e-01   \n","std                    5.589740e-02                    5.265382e-02   \n","min                    4.153846e-01                    4.153846e-01   \n","25%                    5.424702e-01                    5.142857e-01   \n","50%                    6.000000e-01                    5.684211e-01   \n","75%                    6.333333e-01                    5.684211e-01   \n","max                    6.333333e-01                    6.000000e-01   \n","\n","       Degree Centrality Arrival  Degree Centrality Departure       Quarter  \\\n","count               2.817911e+06                 2.817911e+06  2.817911e+06   \n","mean                1.084199e+00                 1.448767e+00  2.478928e+00   \n","std                 4.110768e-01                 1.510912e-01  1.092023e+00   \n","min                 5.333333e-01                 9.666667e-01  1.000000e+00   \n","25%                 6.333333e-01                 1.366667e+00  2.000000e+00   \n","50%                 1.200000e+00                 1.500000e+00  2.000000e+00   \n","75%                 1.500000e+00                 1.533333e+00  3.000000e+00   \n","max                 1.600000e+00                 1.600000e+00  4.000000e+00   \n","\n","            Month_1       Month_2       Month_3  ...  Arrival Hour Bucket  \\\n","count  2.817911e+06  2.817911e+06  2.817911e+06  ...         2.817911e+06   \n","mean   8.084654e-02  7.242702e-02  8.929951e-02  ...         1.516058e+01   \n","std    2.713593e-01  2.580078e-01  2.839153e-01  ...         5.494787e+00   \n","min    0.000000e+00  0.000000e+00  0.000000e+00  ...         0.000000e+00   \n","25%    0.000000e+00  0.000000e+00  0.000000e+00  ...         1.100000e+01   \n","50%    0.000000e+00  0.000000e+00  0.000000e+00  ...         1.600000e+01   \n","75%    0.000000e+00  0.000000e+00  0.000000e+00  ...         2.000000e+01   \n","max    1.000000e+00  1.000000e+00  1.000000e+00  ...         2.300000e+01   \n","\n","          elevation          temp          dwpt          rhum  precip_chance  \\\n","count  2.817911e+06  2.817911e+06  2.817911e+06  2.817911e+06   2.817911e+06   \n","mean   9.260228e+01  1.851464e+01  1.126813e+01  6.575773e+01   9.508711e+00   \n","std    1.085165e+02  8.534309e+00  8.970655e+00  1.884177e+01   2.933353e+01   \n","min    1.300000e+01 -2.290000e+01 -3.510000e+01  7.000000e+00   0.000000e+00   \n","25%    2.900000e+01  1.260000e+01  5.400000e+00  5.200000e+01   0.000000e+00   \n","50%    4.900000e+01  1.910000e+01  1.240000e+01  6.700000e+01   0.000000e+00   \n","75%    1.250000e+02  2.530000e+01  1.870000e+01  8.100000e+01   0.000000e+00   \n","max    5.050000e+02  4.250000e+01  2.810000e+01  1.000000e+02   1.000000e+02   \n","\n","               wdir          wspd          gust  Departure Delay > 15 Min  \n","count  2.817911e+06  2.817911e+06  2.817911e+06              2.817911e+06  \n","mean   1.768204e+02  1.382864e+01  1.382864e+01              5.002433e-01  \n","std    1.092992e+02  8.154236e+00  8.154236e+00              5.000000e-01  \n","min    0.000000e+00  0.000000e+00  0.000000e+00              0.000000e+00  \n","25%    9.000000e+01  7.600000e+00  7.600000e+00              0.000000e+00  \n","50%    1.800000e+02  1.300000e+01  1.300000e+01              1.000000e+00  \n","75%    2.700000e+02  1.840000e+01  1.840000e+01              1.000000e+00  \n","max    3.375000e+02  7.960000e+01  7.960000e+01              1.000000e+00  \n","\n","[8 rows x 37 columns]"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# Split the data into features and target\n","X = non_cancelled_flights[features]\n","print(X.head())\n","y = non_cancelled_flights[target]\n","print(y.head())\n","\n","# Initialize SMOTE with the same random state for reproducibility\n","smote = SMOTE(random_state=42, sampling_strategy='auto')\n","\n","# Apply SMOTE to oversample the minority class\n","X_smote, y_smote = smote.fit_resample(X, y)\n","\n","# Combine oversampled data back into a DataFrame\n","smote_df = pd.DataFrame(X_smote, columns=features)\n","smote_df[target] = y_smote\n","\n","# Balance the dataset size to match the original size\n","# Calculate how many rows to sample from the oversampled dataset\n","sample_size = len(non_cancelled_flights)\n","\n","# Shuffle and downsample to the original size\n","SMOTE_balanced_sample = smote_df.sample(n=sample_size, random_state=89)\n","SMOTE_balanced_sample = shuffle(SMOTE_balanced_sample, random_state=89).reset_index(drop=True)\n","\n","# Describe the balanced dataset\n","print(SMOTE_balanced_sample[target].value_counts())\n","SMOTE_balanced_sample.describe()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Sn8Tutlrr_S","outputId":"86a486dd-2789-40ac-8637-378f565c426f"},"outputs":[{"data":{"text/plain":["['Z:/VT/F24/urban_computing/JetLagged/data/../models//scaler_smote.pkl']"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["X_smote = SMOTE_balanced_sample[features]\n","y_smote = SMOTE_balanced_sample[target]\n","\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X_smote)\n","\n","# Split the dataset into training and testing sets\n","X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_scaled, y_smote, test_size=0.2, random_state=45)\n","path = \"{}/../models/\".format(dir_path)\n","joblib.dump(scaler, '{}/scaler_smote.pkl'.format(path))"]},{"cell_type":"markdown","metadata":{"id":"87no2ksI0Qyn"},"source":["# Training the Models\n","Skip this and load the models if you want to execute predictions!\n","## Decision Tree Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9z_hDzHAchFB","outputId":"74079793-c24d-4e7f-f987-f646c3481827"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree Accuracy: 0.7660861616442978\n","Decision Tree Precision: 0.7460954541488526\n","Decision Tree Recall: 0.8059694458626242\n","Decision Tree F1 Score: 0.7748775708239097\n","[[ 92658  34920]\n"," [ 24703 102612]]\n"]}],"source":["\n","# Split data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train the Decision Tree Classifier\n","tree = DecisionTreeClassifier(random_state=42) # Adjust parameters like max_depth, min_samples_split etc. as needed\n","tree.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = tree.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","# save model\n","path = \"{}/../models/\".format(dir_path)\n","with open(\"{}/decision_tree.pkl\".format(path), \"wb\") as file:\n","    pickle.dump(tree, file)\n","\n","print(f\"Decision Tree Accuracy: {accuracy}\")\n","print(f\"Decision Tree Precision: {precision}\")\n","print(f\"Decision Tree Recall: {recall}\")\n","print(f\"Decision Tree F1 Score: {f1}\")\n","print(str(confusion_matrix(y_test, y_pred)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gY3jACFtrr_S","outputId":"0d4c6b94-d1f7-4c13-aedd-9e43b7255f5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decision Tree Accuracy: 0.8747070085506483\n","Decision Tree Precision: 0.8684248189196265\n","Decision Tree Recall: 0.8831389198514743\n","Decision Tree F1 Score: 0.8757200661061607\n","[[244188  37693]\n"," [ 32920 248782]]\n"]}],"source":["# Initialize and train the Decision Tree Classifier\n","tree_smote = DecisionTreeClassifier(random_state=42) # Adjust parameters like max_depth, min_samples_split etc. as needed\n","tree_smote.fit(X_train_smote, y_train_smote)\n","\n","# Make predictions on the test set\n","y_pred = tree_smote.predict(X_test_smote)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test_smote, y_pred)\n","precision = precision_score(y_test_smote, y_pred)\n","recall = recall_score(y_test_smote, y_pred)\n","f1 = f1_score(y_test_smote, y_pred)\n","\n","# save model\n","path = \"{}/../models/\".format(dir_path)\n","with open(\"{}/decision_tree_smote.pkl\".format(path), \"wb\") as file:\n","    pickle.dump(tree_smote, file)\n","\n","print(f\"Decision Tree Accuracy: {accuracy}\")\n","print(f\"Decision Tree Precision: {precision}\")\n","print(f\"Decision Tree Recall: {recall}\")\n","print(f\"Decision Tree F1 Score: {f1}\")\n","print(str(confusion_matrix(y_test_smote, y_pred)))"]},{"cell_type":"markdown","metadata":{"id":"jG4t7dIX0UVA"},"source":["## Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2wXHrc3eALo","outputId":"8249d31b-9e0e-4473-976a-3b70039f28e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Accuracy: 0.6248504274342567\n","Logistic Regression Precision: 0.6214029603751035\n","Logistic Regression Recall: 0.6370655460864785\n","Logistic Regression F1 Score: 0.6291367869096607\n","[[78162 49416]\n"," [46207 81108]]\n"]}],"source":["# Initialize and train the Logistic Regression model\n","logreg = LogisticRegression(random_state=42, max_iter=1000) # Increase max_iter if needed\n","logreg.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred_logreg = logreg.predict(X_test)\n","\n","# Evaluate the model\n","accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n","precision_logreg = precision_score(y_test, y_pred_logreg)\n","recall_logreg = recall_score(y_test, y_pred_logreg)\n","f1_logreg = f1_score(y_test, y_pred_logreg)\n","\n","# save model\n","#with open(\"{}/logistic.pkl\".format(path), \"wb\") as file:\n","#    pickle.dump(logreg, file)\n","\n","print(f\"Logistic Regression Accuracy: {accuracy_logreg}\")\n","print(f\"Logistic Regression Precision: {precision_logreg}\")\n","print(f\"Logistic Regression Recall: {recall_logreg}\")\n","print(f\"Logistic Regression F1 Score: {f1_logreg}\")\n","print(str(confusion_matrix(y_test, y_pred_logreg)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_LFbwWtrr_S","outputId":"fab98615-016c-4302-ce8c-fd45ea8b1300"},"outputs":[{"name":"stdout","output_type":"stream","text":["Logistic Regression Accuracy: 0.6323097041607004\n","Logistic Regression Precision: 0.6316079645454739\n","Logistic Regression Recall: 0.6344150911246637\n","Logistic Regression F1 Score: 0.6330084157433906\n","[[177643 104238]\n"," [102986 178716]]\n"]}],"source":["# Initialize and train the Logistic Regression model\n","logreg_smote = LogisticRegression(random_state=42, max_iter=1000) # Increase max_iter if needed\n","logreg_smote.fit(X_train_smote, y_train_smote)\n","\n","# Make predictions on the test set\n","y_pred_logreg = logreg_smote.predict(X_test_smote)\n","\n","# Evaluate the model\n","accuracy_logreg = accuracy_score(y_test_smote, y_pred_logreg)\n","precision_logreg = precision_score(y_test_smote, y_pred_logreg)\n","recall_logreg = recall_score(y_test_smote, y_pred_logreg)\n","f1_logreg = f1_score(y_test_smote, y_pred_logreg)\n","\n","# save model\n","with open(\"{}/logistic_smote.pkl\".format(path), \"wb\") as file:\n","    pickle.dump(logreg_smote, file)\n","\n","print(f\"Logistic Regression Accuracy: {accuracy_logreg}\")\n","print(f\"Logistic Regression Precision: {precision_logreg}\")\n","print(f\"Logistic Regression Recall: {recall_logreg}\")\n","print(f\"Logistic Regression F1 Score: {f1_logreg}\")\n","print(str(confusion_matrix(y_test_smote, y_pred_logreg)))"]},{"cell_type":"markdown","metadata":{"id":"5SC7KVzt0Xld"},"source":["## Random Forest Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"wqwm7JcFen9X","outputId":"e1563d91-4f32-4301-c42e-b4fc5f54f525"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Accuracy: 0.7944784674353552\n","Random Forest Precision: 0.7682300802588904\n","Random Forest Recall: 0.8427993559282095\n","Random Forest F1 Score: 0.8037889343341272\n","[[ 95206  32372]\n"," [ 20014 107301]]\n"]}],"source":["# Initialize and train the Random Forest Classifier\n","rf_classifier = RandomForestClassifier(random_state=42, n_estimators=50)\n","rf_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred_rf = rf_classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy_rf = accuracy_score(y_test, y_pred_rf)\n","precision_rf = precision_score(y_test, y_pred_rf)\n","recall_rf = recall_score(y_test, y_pred_rf)\n","f1_rf = f1_score(y_test, y_pred_rf)\n","\n","# save the model\n","with open(\"{}/rforest.pkl\".format(path), \"wb\") as file:\n","    pickle.dump(rf_classifier, file)\n","\n","print(f\"Random Forest Accuracy: {accuracy_rf}\")\n","print(f\"Random Forest Precision: {precision_rf}\")\n","print(f\"Random Forest Recall: {recall_rf}\")\n","print(f\"Random Forest F1 Score: {f1_rf}\")\n","print(str(confusion_matrix(y_test, y_pred_rf)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kftLrVr1rr_T","outputId":"dbfa5098-bfd2-44ba-b3c7-5d816be53e88"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Accuracy: 0.8934478151399173\n","Random Forest Precision: 0.8905648142600887\n","Random Forest Recall: 0.8970614337136407\n","Random Forest F1 Score: 0.8938013189285164\n","[[250828  31053]\n"," [ 28998 252704]]\n"]}],"source":["# Initialize and train the Random Forest Classifier\n","rf_classifier_smote = RandomForestClassifier(random_state=42, n_estimators=50)\n","rf_classifier_smote.fit(X_train_smote, y_train_smote)\n","\n","# Make predictions on the test set\n","y_pred_rf = rf_classifier_smote.predict(X_test_smote)\n","\n","# Evaluate the model\n","accuracy_rf = accuracy_score(y_test_smote, y_pred_rf)\n","precision_rf = precision_score(y_test_smote, y_pred_rf)\n","recall_rf = recall_score(y_test_smote, y_pred_rf)\n","f1_rf = f1_score(y_test_smote, y_pred_rf)\n","\n","# save the model\n","with open(\"{}/rforest_smote.pkl\".format(path), \"wb\") as file:\n","    pickle.dump(rf_classifier_smote, file)\n","\n","print(f\"Random Forest Accuracy: {accuracy_rf}\")\n","print(f\"Random Forest Precision: {precision_rf}\")\n","print(f\"Random Forest Recall: {recall_rf}\")\n","print(f\"Random Forest F1 Score: {f1_rf}\")\n","print(str(confusion_matrix(y_test, y_pred_rf)))"]},{"cell_type":"markdown","metadata":{"id":"q2GHDTl00a_O"},"source":["## XGBoost Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cj_Mzm_ElQ5Z","outputId":"fa7ae251-6b86-4b7b-abfd-cde974557d95"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBoost Accuracy: 0.6642787365678932\n","XGBoost Precision: 0.6693717234999107\n","XGBoost Recall: 0.6478733849114401\n","XGBoost F1 Score: 0.6584471204313864\n","[[86836 40742]\n"," [44831 82484]]\n"]},{"name":"stderr","output_type":"stream","text":["UserWarning: [22:20:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n"]}],"source":["#https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n","\n","# Initialize and train the XGBoost Classifier\n","xgb_classifier = xgb.XGBClassifier(\n","  learning_rate =0.1,\n","  n_estimators=1000,\n","  max_depth=5,\n","  min_child_weight=1,\n","  gamma=0,\n","  subsample=0.8,\n","  colsample_bytree=0.8,\n","  objective= 'binary:logistic',\n","  nthread=4,\n","  scale_pos_weight=1,\n","  seed=27,\n","  eval_metric = 'logloss')\n","xgb_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred_xgb = xgb_classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n","precision_xgb = precision_score(y_test, y_pred_xgb)\n","recall_xgb = recall_score(y_test, y_pred_xgb)\n","f1_xgb = f1_score(y_test, y_pred_xgb)\n","\n","# save model\n","xgb_classifier.save_model(\"{}/xgb.model\".format(path))\n","\n","print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n","print(f\"XGBoost Precision: {precision_xgb}\")\n","print(f\"XGBoost Recall: {recall_xgb}\")\n","print(f\"XGBoost F1 Score: {f1_xgb}\")\n","print(str(confusion_matrix(y_test, y_pred_xgb)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFLvg-Dvrr_T","outputId":"3f81a663-5943-4acf-88b4-59252fca3d83"},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBoost Accuracy: 0.7776334630391619\n","XGBoost Precision: 0.8570971867007673\n","XGBoost Recall: 0.6662004529609303\n","XGBoost F1 Score: 0.749687413864044\n","[[250591  31290]\n"," [ 94032 187670]]\n"]},{"name":"stderr","output_type":"stream","text":["UserWarning: [22:22:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n"]}],"source":["#https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n","\n","# Initialize and train the XGBoost Classifier\n","xgb_classifier_smote = xgb.XGBClassifier(\n","  learning_rate =0.1,\n","  n_estimators=1000,\n","  max_depth=5,\n","  min_child_weight=1,\n","  gamma=0,\n","  subsample=0.8,\n","  colsample_bytree=0.8,\n","  objective= 'binary:logistic',\n","  nthread=4,\n","  scale_pos_weight=1,\n","  seed=27,\n","  eval_metric = 'logloss')\n","xgb_classifier_smote.fit(X_train_smote, y_train_smote)\n","\n","# Make predictions on the test set\n","y_pred_xgb = xgb_classifier_smote.predict(X_test_smote)\n","\n","# Evaluate the model\n","accuracy_xgb = accuracy_score(y_test_smote, y_pred_xgb)\n","precision_xgb = precision_score(y_test_smote, y_pred_xgb)\n","recall_xgb = recall_score(y_test_smote, y_pred_xgb)\n","f1_xgb = f1_score(y_test_smote, y_pred_xgb)\n","\n","# save model\n","xgb_classifier_smote.save_model(\"{}/xgb_smote.model\".format(path))\n","\n","print(f\"XGBoost Accuracy: {accuracy_xgb}\")\n","print(f\"XGBoost Precision: {precision_xgb}\")\n","print(f\"XGBoost Recall: {recall_xgb}\")\n","print(f\"XGBoost F1 Score: {f1_xgb}\")\n","print(str(confusion_matrix(y_test_smote, y_pred_xgb)))"]},{"cell_type":"markdown","metadata":{"id":"cNQ0X_QB0ePO"},"source":["## One Class SVM Outlier Classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":184},"id":"Y8kqt8xtm_cD","outputId":"2584bc27-bccc-4915-b143-74b4be2b5dc3"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nrus = RandomUnderSampler(random_state=42)\\nX_resampled, y_resampled = rus.fit_resample(X, y)\\n\\n\\n# Split the resampled data\\nX_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(\\n    X_resampled, y_resampled, test_size=0.2, random_state=42\\n)\\n\\n# Initialize and train the One-Class SVM\\nocsvm = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"scale\")  # Adjust nu and kernel as needed\\nocsvm.fit(X_train_resampled[y_train_resampled == 0]) # Train only on the negative class (no delay)\\n\\n\\n# Predict on the test set (all points will be either +1 (inlier) or -1(outlier))\\ny_pred_ocsvm = ocsvm.predict(X_test_resampled)\\n\\n\\n# Convert predictions to match the binary classification format (0, 1)\\ny_pred_ocsvm_binary = [0 if pred == 1 else 1 for pred in y_pred_ocsvm]\\n\\n\\n# Evaluate the model\\naccuracy_ocsvm = accuracy_score(y_test_resampled, y_pred_ocsvm_binary)\\nprecision_ocsvm = precision_score(y_test_resampled, y_pred_ocsvm_binary)\\nrecall_ocsvm = recall_score(y_test_resampled, y_pred_ocsvm_binary)\\nf1_ocsvm = f1_score(y_test_resampled, y_pred_ocsvm_binary)\\n\\nwith open(\"{}/ocsvm.pkl\".format(path), \"wb\") as file:\\n    pickle.dump(ocsvm, file)\\n\\nprint(f\"One-Class SVM Accuracy: {accuracy_ocsvm}\")\\nprint(f\"One-Class SVM Precision: {precision_ocsvm}\")\\nprint(f\"One-Class SVM Recall: {recall_ocsvm}\")\\nprint(f\"One-Class SVM F1 Score: {f1_ocsvm}\")\\nprint(str(confusion_matrix(y_test_resampled, y_pred_ocsvm_binary)))\\n'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["#commenting out because this takes forever to run\n","\"\"\"\n","rus = RandomUnderSampler(random_state=42)\n","X_resampled, y_resampled = rus.fit_resample(X, y)\n","\n","\n","# Split the resampled data\n","X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(\n","    X_resampled, y_resampled, test_size=0.2, random_state=42\n",")\n","\n","# Initialize and train the One-Class SVM\n","ocsvm = OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=\"scale\")  # Adjust nu and kernel as needed\n","ocsvm.fit(X_train_resampled[y_train_resampled == 0]) # Train only on the negative class (no delay)\n","\n","\n","# Predict on the test set (all points will be either +1 (inlier) or -1(outlier))\n","y_pred_ocsvm = ocsvm.predict(X_test_resampled)\n","\n","\n","# Convert predictions to match the binary classification format (0, 1)\n","y_pred_ocsvm_binary = [0 if pred == 1 else 1 for pred in y_pred_ocsvm]\n","\n","\n","# Evaluate the model\n","accuracy_ocsvm = accuracy_score(y_test_resampled, y_pred_ocsvm_binary)\n","precision_ocsvm = precision_score(y_test_resampled, y_pred_ocsvm_binary)\n","recall_ocsvm = recall_score(y_test_resampled, y_pred_ocsvm_binary)\n","f1_ocsvm = f1_score(y_test_resampled, y_pred_ocsvm_binary)\n","\n","with open(\"{}/ocsvm.pkl\".format(path), \"wb\") as file:\n","    pickle.dump(ocsvm, file)\n","\n","print(f\"One-Class SVM Accuracy: {accuracy_ocsvm}\")\n","print(f\"One-Class SVM Precision: {precision_ocsvm}\")\n","print(f\"One-Class SVM Recall: {recall_ocsvm}\")\n","print(f\"One-Class SVM F1 Score: {f1_ocsvm}\")\n","print(str(confusion_matrix(y_test_resampled, y_pred_ocsvm_binary)))\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"SJ1s1Csq_VKC"},"source":["## Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jIRLqhys_Wob","outputId":"ea6c5be8-efb0-4486-96cd-ac39890d7b93"},"outputs":[{"name":"stdout","output_type":"stream","text":["Neural Network Accuracy: 0.5605\n","Neural Network Precision: 0.5602\n","Neural Network Recall: 0.5588\n","Neural Network F1 Score: 0.5595\n","[[71718 55860]\n"," [56166 71149]]\n"]}],"source":["# Parameters\n","num_epochs = 100\n","learning_rate = 0.0005\n","hidden_units = 64\n","decay = 0.001\n","\n","\n","x_tensor = torch.FloatTensor(x)\n","y_tensor = torch.FloatTensor(y)\n","\n","# Split data into training and test sets\n","x_train, x_test, y_train, y_test = train_test_split(x_tensor, y_tensor, test_size=0.2, random_state=42)\n","\n","# Define the neural network architecture\n","class weatherNN(nn.Module):\n","    def __init__(self):\n","        super(weatherNN, self).__init__()\n","        self.fc1 = nn.Linear(8, hidden_units)\n","        self.fc2 = nn.Linear(hidden_units, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = self.sigmoid(self.fc2(x))\n","        return x\n","\n","model = weatherNN()\n","\n","# Define the loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    outputs = model(x_train)\n","    loss = criterion(outputs.squeeze(), y_train)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","# Evaluation\n","model.eval()\n","with torch.no_grad():\n","    y_pred_probs = model(x_test)\n","    y_pred = (y_pred_probs.squeeze() > 0.5).float()\n","\n","# Calculate metrics\n","accuracy = accuracy_score(y_test.numpy(), y_pred.numpy())\n","precision = precision_score(y_test.numpy(), y_pred.numpy())\n","recall = recall_score(y_test.numpy(), y_pred.numpy())\n","f1 = f1_score(y_test.numpy(), y_pred.numpy())\n","conf_matrix = confusion_matrix(y_test.numpy(), y_pred.numpy())\n","\n","# Print the results\n","print(f'Neural Network Accuracy: {accuracy:.4f}')\n","print(f'Neural Network Precision: {precision:.4f}')\n","print(f'Neural Network Recall: {recall:.4f}')\n","print(f'Neural Network F1 Score: {f1:.4f}')\n","print(conf_matrix)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}